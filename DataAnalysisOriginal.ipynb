{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "'''*.csv Data Format: ['Case', 'RunTime', 'Object', 'EnterTime', 'Velocity', 'Acceleration']'''\n",
    "import csv, os, numpy as np, pandas as pd, seaborn as sns, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fullpath) -> pd.DataFrame:\n",
    "  df = pd.read_csv(fullpath)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_maximums(df: pd.DataFrame, var_name1:'Case', var_name2: 'Velocity') -> pd.DataFrame:\n",
    "  df_grp = df.groupby(var_name1)\n",
    "  idx = []\n",
    "  for key, key_df in df_grp:\n",
    "    pre_pre_idx = None\n",
    "    pre_pre_var = None\n",
    "    pre_idx = None\n",
    "    pre_var = None\n",
    "    pre_left = False\n",
    "    pre_right = False\n",
    "    for index, row in key_df.iterrows():\n",
    "      if pre_pre_idx is None:\n",
    "        pre_pre_idx = index\n",
    "        pre_pre_var = row[var_name2]\n",
    "      elif pre_idx is None:\n",
    "        pre_idx = index\n",
    "        pre_var = row[var_name2]\n",
    "      else:\n",
    "        cur_var = row[var_name2]\n",
    "        # previous\n",
    "        pre_left = (pre_pre_var <= pre_var)\n",
    "        pre_right = (cur_var <= pre_var)\n",
    "        if pre_left and pre_right:\n",
    "          idx.append(pre_idx)\n",
    "        # update\n",
    "        pre_pre_idx = pre_idx\n",
    "        pre_pre_var = pre_var\n",
    "        pre_idx = index\n",
    "        pre_var = cur_var\n",
    "  return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_minimums(df: pd.DataFrame, var_name1:'Case', var_name2: 'fastcity') -> pd.DataFrame:\n",
    "  df_grp = df.groupby(var_name1)\n",
    "  idx = []\n",
    "  for key, key_df in df_grp:\n",
    "    pre_pre_idx = None\n",
    "    pre_pre_var = None\n",
    "    pre_idx = None\n",
    "    pre_var = None\n",
    "    pre_left = False\n",
    "    pre_right = False\n",
    "    for index, row in key_df.iterrows():\n",
    "      if pre_pre_idx is None:\n",
    "        pre_pre_idx = index\n",
    "        pre_pre_var = row[var_name2]\n",
    "      elif pre_idx is None:\n",
    "        pre_idx = index\n",
    "        pre_var = row[var_name2]\n",
    "      else:\n",
    "        cur_var = row[var_name2]\n",
    "        # previous\n",
    "        pre_left = (pre_pre_var >= pre_var)\n",
    "        pre_right = (cur_var >= pre_var)\n",
    "        if pre_left and pre_right:\n",
    "          idx.append(pre_idx)\n",
    "        # update\n",
    "        pre_pre_idx = pre_idx\n",
    "        pre_pre_var = pre_var\n",
    "        pre_idx = index\n",
    "        pre_var = cur_var\n",
    "  return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile_and_IQR(df: pd.DataFrame) -> list:\n",
    "  # shape (2,1) -> squeeze() -> shape (2,)\n",
    "  [q1, q3] = df.quantile([.25, .75]).squeeze()\n",
    "  IQR = q3-q1\n",
    "  return [q1, q3, IQR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df: pd.DataFrame, col_name, by_case) -> pd.DataFrame:\n",
    "  '''Input: df, target variable's column name, if the removement is by case\n",
    "     Output: df without outlier data\n",
    "     Outliers Calculation: data points < (q1-1.5*IQR) or data points > (q3 + 1.5*IQR)\n",
    "  '''\n",
    "  if by_case:\n",
    "   df_by_case = df.groupby('Case')\n",
    "   df_out = pd.DataFrame(columns=df.columns)\n",
    "   for key, key_df in df_by_case:\n",
    "      [q1, q3, IQR] = get_quantile_and_IQR(key_df[col_name])\n",
    "      temp = key_df[(key_df[col_name] >= q1-1.5*IQR) & (key_df[col_name] <= q3+1.5*IQR)]\n",
    "      df_out = pd.concat([df_out, temp])\n",
    "   return df_out\n",
    "  else:\n",
    "   [q1, q3, IQR] = get_quantile_and_IQR(df[col_name])\n",
    "   return df[(df[col_name] >= q1-1.5*IQR) & (df[col_name] <= q3+1.5*IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Get the data of the inner button's velocity or acceleration\n",
    "2. Delete the outliers and perhaps the positive acceleration\n",
    "3. Calculate the mean\n",
    "'''\n",
    "def get_no_outlier_for_var2(file_path, object_name, var_name1:'RunTime', var_name2: 'Velocity or Acceleration') -> pd.DataFrame:\n",
    "  # Read one csv and extract data of a specific object\n",
    "  df_one = get_data(file_path)\n",
    "  if (var_name2 == \"Acceleration\"):\n",
    "    df_one = df_one[(df_one[var_name2] < 0)]\n",
    "  df_vars = df_one[[var_name1,var_name2]]\n",
    "  df_no_outliers = remove_outliers(df_vars)\n",
    "  return df_no_outliers\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biggest_EnterTime(file_path, var_name1:'Case', var_name2: 'EnterTime'):\n",
    "  df_one = get_data(file_path)\n",
    "  df_vars = df_one[[var_name1,var_name2]]\n",
    "  idx = df_vars.groupby(var_name1)[var_name2].idxmax()\n",
    "  return df_vars.loc[idx,[var_name1,var_name2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crest_for_var2(file_path, var_name1:'Case', var_name2: 'Velocity or Acceleration', AddRunTime, Remove_outlier = True)->pd.DataFrame:\n",
    "  df = get_data(file_path)\n",
    "  df_one = df[[var_name1, var_name2]]\n",
    "  if var_name2 == \"Acceleration\":\n",
    "    df_one = df_one[df_one['Acceleration']<0]\n",
    "  #print(df_one.shape)\n",
    "  if Remove_outlier == True:\n",
    "    #print(var_name2 + \" Outlier Removed\")\n",
    "    df_new = remove_outliers(df_one, var_name2, True)\n",
    "    #print(df_new[var_name2])\n",
    "  else:\n",
    "    #print(var_name2 + \" Outlier Included\")\n",
    "    df_new = df_one\n",
    "    #print(df_new[var_name2])\n",
    "  #print(df_one_no_out.shape)\n",
    "  idx = find_local_minimums(df_new, var_name1, var_name2)\n",
    "  if AddRunTime:\n",
    "    df_one = df[[var_name1, 'RunTime', var_name2]]\n",
    "    df_crest = df_one.loc[idx, [var_name1, 'RunTime', var_name2]]\n",
    "  else:\n",
    "    df_one = df[[var_name1, var_name2]]\n",
    "    df_crest = df_one.loc[idx, [var_name1, var_name2]]\n",
    "  return df_crest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_for_var2(file_path, var_name1:'Case', var_name2: 'Velocity or Acceleration', AddRunTime, Remove_outlier = True)->pd.DataFrame:\n",
    "  df_one = get_data(file_path)\n",
    "  if var_name2 == \"Acceleration\":\n",
    "    df_one = df_one[df_one['Acceleration']<0]\n",
    "  if Remove_outlier == True:\n",
    "    #print(var_name2 + \" Outlier Removed\")\n",
    "    df_new = remove_outliers(df_one, var_name2, True)\n",
    "    #print(df_new[var_name2])\n",
    "  else:\n",
    "    #print(var_name2 + \" Outlier Included\")\n",
    "    df_new = df_one\n",
    "    #print(df_new[var_name2])\n",
    "  idx = find_local_maximums(df_new, var_name1, var_name2)\n",
    "  if AddRunTime:\n",
    "    df_one = df_one[[var_name1, 'RunTime', var_name2]]\n",
    "    df_crest = df_one.loc[idx, [var_name1, 'RunTime', var_name2]]\n",
    "  else:\n",
    "    df_one = df_one[[var_name1, var_name2]]\n",
    "    df_crest = df_one.loc[idx, [var_name1, var_name2]]\n",
    "  return df_crest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot_all_and_crest(x:str, y:str, df_all: pd.DataFrame, df_crest: pd.DataFrame, save_path):\n",
    "  df_all.insert(df_all.shape[1], 'Class', 'all')\n",
    "  df_crest.insert(df_crest.shape[1], 'Class', 'crest')\n",
    "  df_concat = pd.concat([df_all,df_crest])\n",
    "  fig = sns.lineplot(x=x, y=y, hue='Class', data=df_concat)\n",
    "  figure = fig.get_figure()\n",
    "  figure.savefig(save_path, dpi=400)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_by_Case(df: pd.DataFrame, col_name) -> pd.DataFrame:\n",
    "  df_case = pd.DataFrame(columns=['Number','Case','Min','Mean','Max'])\n",
    "  for key, key_df in df:\n",
    "    df_case.loc[len(df_case.index)] = [key[0],key[1],key_df[col_name].min(),key_df[col_name].mean(),key_df[col_name].max()]\n",
    "  return df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230426 - 1 - Cancel\n",
      "230426 - 10 - Cancel\n",
      "230426 - 2 - Cancel\n",
      "230426 - 3 - Cancel\n",
      "230426 - 4 - Cancel\n",
      "230426 - 5 - Cancel\n",
      "230426 - 6 - Cancel\n",
      "230426 - 7 - Cancel\n",
      "230426 - 8 - Cancel\n",
      "230426 - 9 - Cancel\n",
      "LongTapInExecute: []\n",
      "FastTapInExecute: []\n",
      "VelocityInExecute: ['C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 1 - Cancel/020221105-06-53-56-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 1 - Cancel/20221105-06-53-56-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 10 - Cancel/020230422-11-28-31-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 10 - Cancel/20230422-11-28-31-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 2 - Cancel/020221105-06-59-41-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 2 - Cancel/20221105-06-59-41-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 3 - Cancel/020221105-07-04-37-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 3 - Cancel/20221105-07-04-37-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 4 - Cancel/020221105-07-11-48-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 4 - Cancel/20221105-07-11-48-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 5 - Cancel/020221105-07-15-12-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 5 - Cancel/20221105-07-15-12-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 6 - Cancel/020221105-07-20-51-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 6 - Cancel/20221105-07-20-51-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 7 - Cancel/020221105-07-27-57-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 7 - Cancel/20221105-07-27-57-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 8 - Cancel/020221105-07-30-57-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 8 - Cancel/20221105-07-30-57-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 9 - Cancel/020221105-07-34-23-VelocityIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 9 - Cancel/20221105-07-34-23-VelocityIn.csv']\n",
      "AcceInExecute: ['C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 1 - Cancel/020221105-06-53-56-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 1 - Cancel/20221105-06-53-56-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 10 - Cancel/020230422-11-28-31-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 10 - Cancel/20230422-11-28-31-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 2 - Cancel/020221105-06-59-41-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 2 - Cancel/20221105-06-59-41-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 3 - Cancel/020221105-07-04-37-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 3 - Cancel/20221105-07-04-37-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 4 - Cancel/020221105-07-11-48-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 4 - Cancel/20221105-07-11-48-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 5 - Cancel/020221105-07-15-12-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 5 - Cancel/20221105-07-15-12-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 6 - Cancel/020221105-07-20-51-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 6 - Cancel/20221105-07-20-51-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 7 - Cancel/020221105-07-27-57-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 7 - Cancel/20221105-07-27-57-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 8 - Cancel/020221105-07-30-57-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 8 - Cancel/20221105-07-30-57-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 9 - Cancel/020221105-07-34-23-AccelerationIn.csv', 'C:\\\\Users\\\\angel\\\\Desktop\\\\S1DA\\\\Separated - Backtrace - 230422 - study1\\\\Cancel/230426 - 9 - Cancel/20221105-07-34-23-AccelerationIn.csv']\n"
     ]
    }
   ],
   "source": [
    "# File Paths\n",
    "root_dir = r\"C:\\Users\\angel\\Desktop\\S1DA\\Separated - Backtrace - 230422 - study1\\Cancel\"\n",
    "analyze_date = \"221212\"\n",
    "out_dir = root_dir + \" - out\"\n",
    "execute_dir = []\n",
    "cancel_dir = []\n",
    "if not os.path.exists(out_dir):\n",
    "  os.makedirs(out_dir)\n",
    "for dir in os.listdir(root_dir):\n",
    "  print(dir)\n",
    "  if dir.endswith(\"Cancel\"):\n",
    "    cancel_dir.append(dir)\n",
    "    #print(cancel_dir)\n",
    "  elif dir.endswith(\"Execute\"):\n",
    "    execute_dir.append(dir)\n",
    "long_in_csvs = []\n",
    "fast_in_csvs = []\n",
    "velo_in_csvs = []\n",
    "acce_in_csvs = []\n",
    "for dir in cancel_dir:\n",
    "  temp = root_dir+\"/\"+dir\n",
    "  for csv in os.listdir(temp):\n",
    "    temp_csv = temp + \"/\" + csv\n",
    "    if csv.endswith(\"LongTapIn.csv\"):\n",
    "      long_in_csvs.append(temp_csv)\n",
    "    elif csv.endswith(\"FastTapIn.csv\"):\n",
    "      fast_in_csvs.append(temp_csv)\n",
    "    elif csv.endswith(\"VelocityIn.csv\"):\n",
    "      velo_in_csvs.append(temp_csv)\n",
    "    elif csv.endswith(\"AccelerationIn.csv\"):\n",
    "      acce_in_csvs.append(temp_csv)\n",
    "print(\"LongTapInExecute:\",long_in_csvs)\n",
    "print(\"FastTapInExecute:\",fast_in_csvs)\n",
    "print(\"VelocityInExecute:\",velo_in_csvs)\n",
    "print(\"AcceInExecute:\",acce_in_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Biggest Enter Time for Long Tap: nan\n"
     ]
    }
   ],
   "source": [
    "# LongTapTime\n",
    "'''Output: Number (Subject Number) | Case (Enter Case Number) | EnterTime (Selected Biggest EnterTime)'''\n",
    "long_save_name = analyze_date + ' - LongTapTime.csv'\n",
    "long_df = pd.DataFrame(columns=['Number','Case','EnterTime'])\n",
    "for csv in long_in_csvs:\n",
    "  index = csv.split('/')[1].split(' - ')[1]\n",
    "  df = get_biggest_EnterTime(csv, 'Case', 'EnterTime')\n",
    "  df.insert(df.shape[1], 'Number', index)\n",
    "  long_df = pd.concat([long_df,df])\n",
    "long_df = remove_outliers(long_df, 'EnterTime', False)\n",
    "long_df.to_csv(out_dir + '/' + long_save_name, index=False)\n",
    "print(\"Average Biggest Enter Time for Long Tap:\",long_df['EnterTime'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Biggest Enter Time for Fast Tap: nan\n"
     ]
    }
   ],
   "source": [
    "# FastTapTime\n",
    "'''Output: Number (Subject Number) | Case (Enter Case Number) | EnterTime (Selected Biggest EnterTime)'''\n",
    "fast_save_name = analyze_date + ' - FastTapTime.csv'\n",
    "fast_df = pd.DataFrame(columns=['Number','Case','EnterTime'])\n",
    "for csv in fast_in_csvs:\n",
    "  index = csv.split('/')[1].split(' - ')[1]\n",
    "  df = get_biggest_EnterTime(csv, 'Case', 'EnterTime')\n",
    "  df.insert(df.shape[1], 'Number', index)\n",
    "  fast_df = pd.concat([fast_df,df])\n",
    "fast_df = remove_outliers(fast_df, 'EnterTime', False)\n",
    "fast_df.to_csv(out_dir + '/' + fast_save_name, index=False)\n",
    "print(\"Average Biggest Enter Time for Fast Tap:\",fast_df['EnterTime'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velocity for Button Number 4's condition A: 0.5062329337137572\n",
      "Velocity for condition C: 0.8062087410859728\n",
      "Velocity distance: 0.07541025730609403\n",
      "The Velocity of condition A for the seven models:\n",
      "0.2800021617954751\n",
      "0.3554124191015692\n",
      "0.4308226764076632\n",
      "0.5062329337137572\n",
      "0.5816431910198513\n",
      "0.6570534483259453\n",
      "0.7324637056320393\n"
     ]
    }
   ],
   "source": [
    "# Velocity\n",
    "velo_df = pd.DataFrame(columns=['Number','Case','Velocity'])\n",
    "for csv in velo_in_csvs:\n",
    "  index = csv.split('/')[1].split(' - ')[1]\n",
    "  df = pd.read_csv(csv)\n",
    "  df = df[['Case','Velocity']]\n",
    "  df = remove_outliers(df, 'Velocity', True)\n",
    "  df.insert(df.shape[1], 'Number', index)\n",
    "  velo_df = pd.concat([velo_df,df])\n",
    "velo_df_grp = velo_df.groupby(['Number','Case'])\n",
    "velo_by_case = describe_by_Case(velo_df_grp,'Velocity')\n",
    "velo_min_mean = velo_by_case['Min'].mean()\n",
    "velo_mean_mean = velo_by_case['Mean'].mean()\n",
    "velo_max_mean = velo_by_case['Max'].mean()\n",
    "velo_df.to_csv(out_dir + '/' + analyze_date + ' - Velo_no_outliers.csv', index=False)\n",
    "velo_by_case.to_csv(out_dir + '/' + analyze_date + ' - Velo_by_case.csv', index=False)\n",
    "velo_dist = (velo_mean_mean - velo_min_mean)/3\n",
    "print(\"Velocity for Button Number 4's condition A:\",velo_mean_mean)\n",
    "print(\"Velocity for condition C:\", velo_max_mean)\n",
    "print(\"Velocity distance:\", velo_dist)\n",
    "print(\"The Velocity of condition A for the seven models:\")\n",
    "for i in range(-3,4):\n",
    "  print(velo_mean_mean + velo_dist * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceleration for Button Number 4's condition B: -21.109126356543015\n",
      "Acceleration distance: -3.5893254010289315\n",
      "The Acceleration for the seven models:\n",
      "-10.341150153456221\n",
      "-13.930475554485152\n",
      "-17.519800955514086\n",
      "-21.109126356543015\n",
      "-24.698451757571945\n",
      "-28.28777715860088\n",
      "-31.87710255962981\n"
     ]
    }
   ],
   "source": [
    "# Acceleration\n",
    "acce_df = pd.DataFrame(columns=['Number','Case','Acceleration'])\n",
    "for csv in acce_in_csvs:\n",
    "  #rint(csv)\n",
    "  index = csv.split('/')[1].split(' - ')[1]\n",
    "  #rint(index)\n",
    "  df = pd.read_csv(csv)\n",
    "  df = df[['Case','Acceleration']]\n",
    "  df = df[df['Acceleration']<-0.5841011435740535]\n",
    "  df = remove_outliers(df, 'Acceleration', True)\n",
    "  df.insert(df.shape[1], 'Number', index)\n",
    "  acce_df = pd.concat([acce_df,df])\n",
    "  #print(acce_df)\n",
    "acce_df_grp = acce_df.groupby(['Number','Case'])\n",
    "acce_by_case = describe_by_Case(acce_df_grp,'Acceleration')\n",
    "acce_min_mean = acce_by_case['Min'].mean()\n",
    "acce_mean_mean = acce_by_case['Mean'].mean()\n",
    "acce_max_mean = acce_by_case['Max'].mean()\n",
    "acce_df.to_csv(out_dir + '/' + analyze_date + ' - Acce_no_outliers.csv', index=False)\n",
    "acce_by_case.to_csv(out_dir + '/' + analyze_date + ' - Acce_by_case.csv', index=False)\n",
    "acce_dist = (acce_mean_mean - acce_max_mean)/3\n",
    "print(\"Acceleration for Button Number 4's condition B:\",acce_mean_mean)\n",
    "print(\"Acceleration distance:\",acce_dist)\n",
    "print(\"The Acceleration for the seven models:\")\n",
    "for i in range(-3,4):\n",
    "  print(acce_mean_mean + acce_dist * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Number, Case, Acceleration]\n",
      "Index: []\n",
      "Acceleration for Button Number 4's condition B: -21.602520829986943\n",
      "Acceleration distance: -3.8217620210555556\n",
      "The Acceleration for the seven models:\n",
      "-10.137234766820276\n",
      "-13.958996787875833\n",
      "-17.780758808931388\n",
      "-21.602520829986943\n",
      "-25.4242828510425\n",
      "-29.246044872098054\n",
      "-33.06780689315361\n"
     ]
    }
   ],
   "source": [
    "# Acceleration\n",
    "acce_df = pd.DataFrame(columns=['Number','Case','Acceleration'])\n",
    "print(acce_df)\n",
    "for csv in acce_in_csvs:\n",
    "  #print(csv)\n",
    "  csv_name = csv.split('/')[2].split(\".\")[0]\n",
    "  #print(csv_name)\n",
    "  index = csv.split('/')[1].split(' - ')[1]\n",
    "  #print(index)\n",
    "  df = pd.read_csv(csv)\n",
    "  df = df[['Case','Acceleration']]\n",
    "  df = df[df['Acceleration']<-0.5841011435740535]\n",
    "  #df = remove_outliers(df, 'Acceleration', True)\n",
    "  df.insert(df.shape[1], 'Number', index)\n",
    "  acce_df = pd.concat([acce_df,df])\n",
    "  #acce_df.to_csv(r\"C:\\Users\\angel\\Desktop\\S1DA\\Separated - Backtrace - 230422 - study1\\raw\" + \"\\\\\" + csv_name + \" - raw.csv\" , index = False)\n",
    "acce_df_grp = acce_df.groupby(['Number','Case'])\n",
    "acce_by_case = describe_by_Case(acce_df_grp,'Acceleration')\n",
    "acce_min_mean = acce_by_case['Min'].mean()\n",
    "acce_mean_mean = acce_by_case['Mean'].mean()\n",
    "acce_max_mean = acce_by_case['Max'].mean()\n",
    "acce_df.to_csv(out_dir + '/' + analyze_date + ' - Acce_no_outliers.csv', index=False)\n",
    "acce_by_case.to_csv(out_dir + '/' + analyze_date + ' - Acce_by_case.csv', index=False)\n",
    "acce_dist = (acce_mean_mean - acce_max_mean)/3\n",
    "print(\"Acceleration for Button Number 4's condition B:\",acce_mean_mean)\n",
    "print(\"Acceleration distance:\",acce_dist)\n",
    "print(\"The Acceleration for the seven models:\")\n",
    "for i in range(-3,4):\n",
    "  print(acce_mean_mean + acce_dist * i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Case</th>\n",
       "      <th>Acceleration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>-13.988710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.201226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>-3.037988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>-2.623502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>-13.774800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>-36.134250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>-42.748990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-19.209770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.276043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>-40.287270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number Case  Acceleration\n",
       "0        1   11    -13.988710\n",
       "2        1   11     -2.201226\n",
       "4        1   11     -3.037988\n",
       "8        1   12     -2.623502\n",
       "10       1   12    -13.774800\n",
       "..     ...  ...           ...\n",
       "199      9   29    -36.134250\n",
       "201      9   29    -42.748990\n",
       "203      9   30    -19.209770\n",
       "204      9   30     -1.276043\n",
       "206      9   30    -40.287270\n",
       "\n",
       "[1719 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acce_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No outlier\n",
    "\n",
    "Acceleration for Button Number 4's condition B: -4.749872072703843\n",
    "Acceleration distance: -1.5004264088416142\n",
    "The Acceleration for the seven models:\n",
    "-0.24859284617900013\n",
    "-1.7490192550206145\n",
    "-3.249445663862229\n",
    "-4.749872072703843\n",
    "-6.250298481545457\n",
    "-7.750724890387071\n",
    "-9.251151299228685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original\n",
    "\n",
    "Acceleration for Button Number 4's condition B: -3.101236399826085\n",
    "Acceleration distance: -0.9508811845490283\n",
    "The Acceleration for the seven models:\n",
    "-0.24859284617900013\n",
    "-1.1994740307280283\n",
    "-2.1503552152770564\n",
    "-3.101236399826085\n",
    "-4.052117584375113\n",
    "-5.002998768924141\n",
    "-5.9538799534731695"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No outlier and under -0.5841011435740535\n",
    "\n",
    "Acceleration for Button Number 4's condition B: -6.000815429471779\n",
    "Acceleration distance: -1.614556699490593\n",
    "The Acceleration for the seven models:\n",
    "-1.1571453309999997\n",
    "-2.771702030490593\n",
    "-4.386258729981186\n",
    "-6.000815429471779\n",
    "-7.615372128962372\n",
    "-9.229928828452966\n",
    "-10.844485527943558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5841011435740535"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.5841011435740535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four - removed Outlier\n",
    "\n",
    "Acceleration for Button Number 4's condition B: -2.7191131912123083\n",
    "Acceleration distance: -0.8772874907632695\n",
    "The Acceleration for the seven models:\n",
    "-0.0872507189224998\n",
    "-0.9645382096857693\n",
    "-1.8418257004490388\n",
    "-2.7191131912123083\n",
    "-3.596400681975578\n",
    "-4.473688172738847\n",
    "-5.350975663502117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four - With Outlier\n",
    "\n",
    "Acceleration for Button Number 4's condition B: -5.417435556383105\n",
    "Acceleration distance: -1.776728279153535\n",
    "The Acceleration for the seven models:\n",
    "-0.08725071892250025\n",
    "-1.863978998076035\n",
    "-3.64070727722957\n",
    "-5.417435556383105\n",
    "-7.19416383553664\n",
    "-8.970892114690175\n",
    "-10.747620393843711"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four - under stay stats and with outlier \n",
    "\n",
    "Acceleration for Button Number 4's condition B: -7.05007819496449\n",
    "Acceleration distance: -2.07625984915483\n",
    "The Acceleration for the seven models:\n",
    "-0.8212986475000008\n",
    "-2.8975584966548302\n",
    "-4.97381834580966\n",
    "-7.05007819496449\n",
    "-9.12633804411932\n",
    "-11.202597893274149\n",
    "-13.278857742428979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 2)\n",
      "Mean Peak: -1.4548591345543445 With Outlier\n",
      "Mean Crest: -7.397563634900542 With Outlier\n",
      "----------------------上方有异常值，下方执行了去异常值------------------------\n",
      "Mean Peak: -1.3304148157777973 Without Outlier\n",
      "Mean Crest: -5.766969017948718 Without Outlier\n"
     ]
    }
   ],
   "source": [
    "# Get Peak for execute\n",
    "\n",
    "peak_dfs_with_outlier = []\n",
    "crest_dfs_with_outlier = []\n",
    "\n",
    "crest_dfs_wt_outlier = []\n",
    "peak_dfs_wt_outlier = []\n",
    "\n",
    "fPath = r\"C:\\Users\\angel\\Desktop\\S1DA\\Separated - Backtrace - 230422 - study1\\Execute\"\n",
    "\n",
    "for f in os.listdir(fPath):\n",
    "    New_fPath = os.path.join(fPath, f)\n",
    "    for csvs in os.listdir(New_fPath):\n",
    "        csvs_full_path = os.path.join(New_fPath, csvs)\n",
    "        #print(csvs_full_path)\n",
    "        df_peak_wt_outlier = get_peak_for_var2(csvs_full_path, \"Case\", \"Acceleration\", False, False)\n",
    "        df_crest_wt_outlier = get_crest_for_var2(csvs_full_path, \"Case\", \"Acceleration\", False, False)\n",
    "        peak_dfs_wt_outlier.append(df_peak_wt_outlier)\n",
    "        crest_dfs_wt_outlier.append(df_crest_wt_outlier)\n",
    "        \n",
    "        df_peak_with_outlier = get_peak_for_var2(csvs_full_path, \"Case\", \"Acceleration\", False, True)\n",
    "        df_crest_with_outlier = get_crest_for_var2(csvs_full_path, \"Case\", \"Acceleration\", False, True)\n",
    "        peak_dfs_with_outlier.append(df_peak_with_outlier)\n",
    "        crest_dfs_with_outlier.append(df_crest_with_outlier)\n",
    "\n",
    "combined_peak_dfs_wt_outlier = pd.concat(peak_dfs_wt_outlier, ignore_index=True)\n",
    "combined_crest_dfs_wt_outlier = pd.concat(crest_dfs_wt_outlier, ignore_index=True)\n",
    "\n",
    "combined_peak_dfs_with_outlier = pd.concat(peak_dfs_with_outlier, ignore_index=True)\n",
    "combined_crest_dfs_with_outlier = pd.concat(crest_dfs_with_outlier, ignore_index=True)\n",
    "\n",
    "Mean_peak_wt_outlier = combined_peak_dfs_wt_outlier[\"Acceleration\"].mean()\n",
    "Mean_Crest_wt_outlier = combined_crest_dfs_wt_outlier[\"Acceleration\"].mean()\n",
    "\n",
    "Mean_peak_with_outlier = combined_peak_dfs_with_outlier[\"Acceleration\"].mean()\n",
    "Mean_Crest_with_outlier = combined_crest_dfs_with_outlier[\"Acceleration\"].mean()\n",
    "\n",
    "print(combined_peak_dfs.shape)\n",
    "print(\"Mean Peak: \" + str(Mean_peak_wt_outlier) + \" With Outlier\")\n",
    "print(\"Mean Crest: \" + str(Mean_Crest_wt_outlier) + \" With Outlier\")\n",
    "print(\"----------------------上方有异常值，下方执行了去异常值------------------------\")\n",
    "print(\"Mean Peak: \" + str(Mean_peak_with_outlier) + \" Without Outlier\")\n",
    "print(\"Mean Crest: \" + str(Mean_Crest_with_outlier) + \" Without Outlier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crest_peak_cal(path, var: \"Velocity or Acceleration\"):\n",
    "    peak_dfs_with_outlier = []\n",
    "    crest_dfs_with_outlier = []\n",
    "\n",
    "    crest_dfs_wt_outlier = []\n",
    "    peak_dfs_wt_outlier = []\n",
    "\n",
    "    for f in os.listdir(path):\n",
    "        New_path = os.path.join(path, f)\n",
    "        for csvs in os.listdir(New_path):\n",
    "            csvs_full_path = os.path.join(New_path, csvs)\n",
    "            #print(csvs_full_path)\n",
    "            df_peak_wt_outlier = get_peak_for_var2(csvs_full_path, \"Case\", var, False, False)\n",
    "            df_crest_wt_outlier = get_crest_for_var2(csvs_full_path, \"Case\", var, False, False)\n",
    "            peak_dfs_wt_outlier.append(df_peak_wt_outlier)\n",
    "            crest_dfs_wt_outlier.append(df_crest_wt_outlier)\n",
    "\n",
    "            df_peak_with_outlier = get_peak_for_var2(csvs_full_path, \"Case\", var, False, True)\n",
    "            df_crest_with_outlier = get_crest_for_var2(csvs_full_path, \"Case\", var, False, True)\n",
    "            peak_dfs_with_outlier.append(df_peak_with_outlier)\n",
    "            crest_dfs_with_outlier.append(df_crest_with_outlier)\n",
    "\n",
    "    combined_peak_dfs_wt_outlier = pd.concat(peak_dfs_wt_outlier, ignore_index=True)\n",
    "    combined_crest_dfs_wt_outlier = pd.concat(crest_dfs_wt_outlier, ignore_index=True)\n",
    "\n",
    "    combined_peak_dfs_with_outlier = pd.concat(peak_dfs_with_outlier, ignore_index=True)\n",
    "    combined_crest_dfs_with_outlier = pd.concat(crest_dfs_with_outlier, ignore_index=True)\n",
    "\n",
    "    Mean_peak_wt_outlier = combined_peak_dfs_wt_outlier[var].mean()\n",
    "    Mean_Crest_wt_outlier = combined_crest_dfs_wt_outlier[var].mean()\n",
    "\n",
    "    Mean_peak_with_outlier = combined_peak_dfs_with_outlier[var].mean()\n",
    "    Mean_Crest_with_outlier = combined_crest_dfs_with_outlier[var].mean()\n",
    "\n",
    "    #print(combined_peak_dfs.shape)\n",
    "    print(\"Calculating \" +var +\" Mean Peak: \" + str(Mean_peak_wt_outlier) + \" With Outlier\")\n",
    "    print(\"Calculating \" +var +\" Mean Crest: \" + str(Mean_Crest_wt_outlier) + \" With Outlier\")\n",
    "    print(\"----------------------上方有异常值，下方执行了去异常值------------------------\")\n",
    "    print(\"Calculating \" +var +\" Mean Peak: \" + str(Mean_peak_with_outlier) + \" Without Outlier\")\n",
    "    print(\"Calculating \" +var +\" Mean Crest: \" + str(Mean_Crest_with_outlier) + \" Without Outlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Acceleration Mean Peak: -0.30658765441896035 With Outlier\n",
      "Calculating Acceleration Mean Crest: -1.4508537367125083 With Outlier\n",
      "----------------------上方有异常值，下方执行了去异常值------------------------\n",
      "Calculating Acceleration Mean Peak: -0.2207577438622766 Without Outlier\n",
      "Calculating Acceleration Mean Crest: -1.0146284264895105 Without Outlier\n",
      "                                                           \n",
      "Calculating Velocity Mean Peak: 0.040996547758299355 With Outlier\n",
      "Calculating Velocity Mean Crest: 0.01718010138194485 With Outlier\n",
      "----------------------上方有异常值，下方执行了去异常值------------------------\n",
      "Calculating Velocity Mean Peak: 0.027831800307618126 Without Outlier\n",
      "Calculating Velocity Mean Crest: 0.012068016788360128 Without Outlier\n"
     ]
    }
   ],
   "source": [
    "pathf = r\"C:\\Users\\angel\\Desktop\\S1DA\\veloAnalysation\\StayVelo\"\n",
    "crest_peak_cal(pathf, \"Acceleration\")\n",
    "print(\"                                                           \")\n",
    "crest_peak_cal(pathf, \"Velocity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c16110b125a1a94a0c2ee36b618f58d8df3bdc0e9bdb6e59d7d98f911f4af16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
